<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <link rel="stylesheet" type="text/css" href="html.css" />
    <title>jas project web log</title>
  </head>
  <body class="main">
    <h1>JAS web-log</h1>

<dl>
<!--
<dt>2008, 1,  </dt>
<dd> 
</dd>
-->

<dt>2008, 9, 28</dt>
<dd> 
 Implemented univariate power series during ADG2008 
 as <code>RingElem</code> and <code>RingFactory</code> types 
 in package <code>edu.jas.ps</code> 
 in classes <code>UnivPowerSeries</code> and <code>UnivPowerSeriesRing</code>.
 The implementation follows the "Infinite Streams in Java" paper of D. Gruntz
 in PPPJ2006.
</dd>

<dt>2008, 8, 11</dt>
<dd> 
 Added jython html documentation generated by epydoc.
 Added jython module to allow native polynomial expression input.
</dd>

<dt>2008, 8, 8</dt>
<dd> 
 New release 2.2. 
 Implemented interface to use JAS as an meditor engine,  
 see <a href="http://jscl-meditor.sourceforge.net/" target="rela">jscl-meditor</a>.
</dd>

<dt>2008, 7 </dt>
<dd> 
 Finished implementation of comprehensive Groebner bases via Groebner systems.
 Object oriented class layout uses <code>Condition</code>
 and <code>ColoredSystem</code> classes. 
 <code>Condition</code>s consist of an ideal 
 (with lazy Groebner base computation) for the conditions equal to zero 
 and a multiplicative set for the conditions not equal to zero.
 Non-zero condition polynomials are reduced modulo the ideal of 
 condition zero polynomials. 
 The squarefree part from both condition polynomials is used.
 It differs from the MAS implementation by Schoenfeld, Pesch and others 
 by the ideal used to store the zero conditions and some more details. 
</dd>

<dt>2008, 6 </dt>
<dd> 
 Added dimension computation to Ideal.
 Added term order optimization method to Ideal.
 Refactored ExpVector for different storage unit implementations of the exponent arrays.
 Supported storage units are <code>long</code>, 
 <code>int</code> (now the default, as seems to be the fastest), 
 <code>short</code> and <code>byte</code>.
 The respective classes are <code>ExpVectorLong</code>, 
 <code>ExpVectorInteger</code>,
 <code>ExpVectorShort</code> and <code>ExpVectorByte</code>.
</dd>

<dt>2008, 1 and 2</dt>
<dd> 
 Added Groebner bases for polynomial rings over regular rings
 <code>RGroebnerBaseSeq</code> and <code>RGroebnerBasePseudoSeq</code>.
 Refactorings and fixes.
</dd>

<dt>2007, 11 and 12</dt>
<dd> 
 Added von Neuman regular rings as (finite) direct products of rings,
 <code>Product</code> and <code>RegularRingElem</code>.
 Added fraction free pseudo reduction and Groebner bases
 <code>GroebnerBasePseudoSeq</code>.
 Minor refactorings and fixes.
</dd>

<dt>2007, 10, 13</dt>
<dd> 
 Added Groebner bases in polynomial rings over principal ideal domains 
 and Euclidean domains, so called D- and E-Groebner bases,
 <code>DGroebnerBaseSeq</code> and <code>EGroebnerBaseSeq</code>.
 Added test methods for reducibility and refactored sequential 
 Groebner base implementations.
</dd>

<dt>2007, 9, 20</dt>
<dd> 
 Minor refactorings and fixes.
 Modular rational functions and related conversions.
</dd>

<dt>2007, 8, 19</dt>
<dd> 
 Added term order optimization for 
 polynomial and rational function coefficients.
</dd>

<dt>2007, 8, 12</dt>
<dd> 
 Cleanup of UFD code and subversion exports. 
 Term order optimization also available in jython.
</dd>

<dt>2007, 7, 28</dt>
<dd> 
 Added term order optimization class from old DIP/MAS system.
 This introduced a dependency on JDK 1.6.
 Refactored source tree to allow fully functional subversion exports.
</dd>

<dt>2007, 7, 12</dt>
<dd> 
  New global class edu.jas.kern.ComputerThreads to represent a thread pool.
  To stop JAS, when the pool has been started, it is required 
  to call ComputerThreads.terminate().
</dd>

<dt>2007, 7, 11</dt>
<dd> 
  New preemptive cancellation handling. 
  Introduced class PreemptingException as runtime exception and 
  a global class PreemptStatus to allow or deny preemption cancellation.
  GenPolynomialRing queries PreemptStatus upon creation.
  GenPolynomial checks preempt cancellation handling and thread interrupt status
  on construction. If preemption is requested, it throws PreemptingException.
  This allows e.g. GCDProxy to ignore the respective sub-task and get the thread free.
  Removed explicit isInterrupted() checks in edu.jas.ufd package.
</dd>

<dt>2007, 7, 10</dt>
<dd> 
  Refactored generation of (lists of) univariate polynomials
  from SolvableGroebnerBase* to GenSolvablePolynomialRing and GenPolynomialRing.
  Implemented generic Power class in edu.jas.structure, 
  refactored power() in subresultant PRS.
</dd>

<dt>2007, 7, 9</dt>
<dd> 
  Added unit tests for distributive law in arith and poly packages.
  Review of all documentation comments.
</dd>

<dt>2007, 7, 8</dt>
<dd> 
  Added assertions to check for number of polynomial variables in GenPolynomial.
  In ModInteger and AlgebraicNumber inverse() now throws a NotInvertibleExecption,
  which extends runtime exception.
  Fixed some correctness bugs detected by Findbugs.
</dd>

<dt>2007, 7, 7</dt>
<dd> 
 Refactored ModInteger for ModIntegerRing factory.
 Changed all depending classes.
</dd>

<dt>2007, 7, -6</dt>
<dd> 
 Refactored GenPolynomial.getMap() to return unmodifiable SortedMap.
 Refactored GenPolynomial.val using methods from jas.ufd package to jas.poly package.
 ExpVector.getVal() renamed and made package private.
 Logger variables now also final.
</dd>

<dt>2007, 6, 10</dt>
<dd> 
 Improved InterruptedException handling.
</dd>

<dt>2007, 6, 4</dt>
<dd> 
 Refactored use of edu.ky.parallel package to use edu.jas.util and 
 java.util.concurrent.
</dd>

<dt>2007, 6, 2</dt>
<dd> 
 Refactored project web-site.
</dd>

<dt>2007, 2-5 </dt>
<dd> 
 Implementation of greatest common divisor algorithms.
 Using recursive types.
 Implemented remainder sequences: primitive, monic, subresultant.
 Implemented modular methods with chinese remaindering for ModIntegers 
 and evaluation in finite fields to reduce the number of variables.
 Implemented Hensel lifting: linear and quadratic; mod ideal is still missing.
 Factory classes to select "best" implementations.
 Proxy classes to run probable good implementations in parallel,
 taking the result of the first terminating algorithm.
 Refactored many classes to fit for the new requirements.
 New method characteristic() in RingFactory and implementing classes.
 Changed Quotient (rational function) to use new gcd algorithms.
 Can compute GBs for polynomials with rational function coefficients.
</dd>

<dt>2006, 3, 2 </dt>
<dd> 
 Refactored ring package to separate application package with 
 more application of Groebner bases oriented classes.
 The ring package could now be renamed to gb package. 
 Cosmetic and documentation improvements, 
 e.g. javadoc package descriptions and type parameter tags,
 removed all tabs in all java files.
 Implemented generic Quotient(Ring), Residue(Ring) and Local(Ring).
</dd>

<dt>2006, 2, 27 </dt>
<dd> 
 Implemented parallel solvable Groebner base algorithms and tests.
 New class distributed ThreadPool.
 Cosmetic and code improvements spotted by eclipse, lint4j and jdepend.
 Refactored module package to separate vector package with 
 basic linear algebra and list handling classes.
</dd>

<dt>2006, 2, 19 </dt>
<dd> 
 Refactored to allow different Groebner base or reduction engines 
 where appropriate. 
 Split Syzygy etc. to an interface and a class.
 Factored basic linear algebra out of Syzygy etc.
 Adapted jython files to Jave code refactorings.
 Reorganized jar files and documentation.
</dd>


<dt>2006, 2, 12 </dt>
<dd> 
 Moved old examples to MAS subdirectory and new examples 
 to examples directory.
 Implemented some right version algorithms using opposite rings.
</dd>

<dt>2006, 2, 4 </dt>
<dd> 
 Switched to subversion from cvs.
 Fixed bugs in new left syzygy algorithm.
</dd>

<dt>2006, 1, 14-29 </dt>
<dd> 
 More documentation and cosmetic.
 Implementation of an extended Groebner Base algorithm
 and arbitrary base syzygy computation.
</dd>

<dt>2006, 1, 6 </dt>
<dd> 
 GenPolynomialTokenizer enhanced to parse algebraic number 
 and Galois field coefficients.
 Fixed an error in leftNormalform.
</dd>

<dt>2005, 12, 30</dt>
<dd> 
 New classes CriticalPair and CriticalPairList replace OrderedPairlist.
 Reworked GB parallel and distributed versions to better respect
 sequential version critical pair sequences.
 Fixed some race conditions in parallel and distributed algorithms.
</dd>

<dt>2005, 12, 28</dt>
<dd> 
 Refactored all classes to remove static methods.
 So to use any method at first an appropriate object is required.
 Also class organization has changed to interfaces, abstract classes 
 and concrete classes, e.g. GroebnerBase, GroebnerBaseAbstract,
 GroebnerBaseSeq, GroebnerBaseParallel and GroebnerBaseDistributed.   
</dd>


<dt>2005, 12, 27</dt>
<dd> 
 Implemented new Ideal class with some ideal operations
 like sum, product, intersection and quotient.
 Added TermOrder extension and contraction.
</dd>


<dt>2005, 11-12 </dt>
<dd>
 Updated documentation comments.
</dd>


<dt>2005, 7, 24</dt>
<dd> 
 Updated old Java JDK 1.4 branch.
 Bugfixes (in twoSidedGB), minor changes and cosmetic.
 <br />
 Updated documentation for new Java JDK 1.5 branch.
</dd>


<dt>2005, 5-7</dt>
<dd> 
 Working through all classes to introduce type parameters
 and making all implied modifications. 
</dd>


<dt>2005, 5, 5</dt>
<dd> 
 Switched to Java 1.5. 
 Now using covariant returns for implemented interfaces.
</dd>


<dt>2005, 3, 25-29</dt>
<dd> 
 Some module algorithms implemented. 
 Activated project web pages.
</dd>

<dt>2005, 3, 12-19</dt>
<dd> 
 Some Syzygy algorithms implemented. 
 Cosmetic on comments and forked web-log.
</dd>


<dt>2005, 3, 5</dt>
<dd> 
 For the python languege and interpreter exists also a Java 
 version named jython. This system can directly access Java classes 
 and execute Java methods. 
 Added some jython modules Ring, Ideal, SolvRing and SolvIdeal, 
 to access jas GB algorithms from jython.
</dd>

<dt>2005, 2, 25-28</dt>
<dd> 
 Penality of commutative GB computed as non-commutative left GB
 is about 24% for (graded) Katsura 6 to 74% for (graded) Katsura 5.
 Commutative GB computed as non-commutative twosided GB
 is about a factor of 4 for (graded) Katsura 5 to a factor of 9 
 for (graded) Katsura 5.

 Penality for weighted degree term order compated to graded Term order
 is not measurable or sometimes better.
 Fixed error in polynomial getONE() to correct term order. 
 Parser for non-commutative problems with relation tables 
 (but only commutative representations) and RunSGB main routine.
</dd>

<dt>2005, 2, 14-21</dt>
<dd> 
  New TermOrder with direct generation of Comparators for 
  ExpVector comparisons. Split term orders (elimination orders)
  and weighted degree orders.
</dd>

<dt>2005, 2, 4-8</dt>
<dd> 
  New unit test case for TermOrder.
  Fixed weak point in polynomial getONE() to correct number 
  of variables, e.g. correct exponent vector size.
  Polynomial constant ONE still has wrong exponent vector size.
  Deleted many old polynomial classes.
<p>
  Implemented noncommutative product for solvable polynomials,
  together with relation tables. 
  SolvableOrderedMapPolynomial extends OrderedMapPolynomial.
  RatSolvableOrderedMapPolynomial extends SolvableOrderedMapPolynomial.
  Interface SolvablePolynomial extends Ordered Polynomial.
  Some more left multiplication methods, left reduction and 
  left Groebner Bases, twosided Groebner Base test and computation.
  Pairlist class changed to avoid usage of criterion 4 if running
  for SolvablePolynomials, also criterion4() method itself checks 
  for SolvablePolynomials.
</p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="relation table timings 1" >
<caption>RelationTable timings I, U(sl_3)</caption>
<tr>
<th>run / n</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
<th>8</th>
<th>9</th>
<th>10</th>
<th>11</th>
<th>12</th>
<th>13</th>
<th>14</th>
<th>15</th>
</tr>
<tr align="right">
<th>first</th>
<td> 3</td>
<td> 13</td>
<td> 32</td>
<td> 92</td>
<td> 128</td>
<td> 188</td>
<td> 274</td>
<td> 420</td>
<td> 683</td>
<td> 1126</td>
<td> 1795</td>
<td> 2793</td>
<td> 4380</td>
<td> 6741</td>
</tr>
<tr align="right">
<th>second</th>
<td> 0</td>
<td> 1</td>
<td> 2</td>
<td> 3</td>
<td> 4</td>
<td> 5</td>
<td> 6</td>
<td> 8</td>
<td> 10</td>
<td> 13</td>
<td> 16</td>
<td> 21</td>
<td> 27</td>
<td> 35</td>
</tr>
</table>
</div>
<p>
  Timings in ms on AMD XP 2800+.
  Computation of (Y^n) * (X^n) with respect to the relation
  Y * X = X Y - H.
  In the first run the relation table is populated with the 
  products Y^i * X^i, i = 2,...,n.
  In the second run the relations are reused, showing almost
  no computing time anymore for the products.
</p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="relation table timings 2" >
<caption>RelationTable timings II, U(sl_3)</caption>
<tr>
<th>run / n</th>
<th>2</th>
<th>3</th>
<th>4</th>
<th>5</th>
<th>6</th>
<th>7</th>
</tr>
<tr align="right">
<th>first</th>
<td> 28</td>
<td> 94</td>
<td> 303</td>
<td> 1234</td>
<td> 5185</td>
<td> 24647</td>
</tr>
<tr align="right">
<th>second</th>
<td> 1</td>
<td> 12</td>
<td> 107</td>
<td> 782</td>
<td> 4569</td>
<td> 23897</td>
</tr>
</table>
</div>
<p>
  Second example shows the computation of 
  ( Xa + Xb + Xc + Ya + Yb + Yc + Ha + Hb )^n
  in U(sl_3).
  Since in the relation table only products of two variables 
  are stored, the improvement is minimal (for low n).
</p>
</dd>

<dt>2005, 1, 24-31</dt>
<dd> 
  Removed old deprecated classes.
  Todo: let DistHashTable implement Map Interface.
  Reimplemented Reduction.Normalform so that asynchronous 
  update of the polynomial list is possible and respected.
  In case a new polynomial arrives, the reduction is restarted 
  from the beginning. Continuing with the done work and 
  rereducing so far irreducible terms would be an alternative.
  Todo: use JDK 1.5 java.util.concurrent with interference free Lists,
  BlockingQueues.

<div align="center" >
<table border="1" cellpadding="10"
       summary="distributed timings k6g" >
<caption>Distributed computation timings, Katsura 6 (G)</caption>
<tr>
<th># Threads <br /> CPUs</th>
<th># JVMs</th>
<th>time (sec)</th>
<th>#put</th>
<th>#remove</th>
<th>% total</th>
</tr>
<tr align="right">
<td>1, seq</td>
<td>1</td>
<td>160.2</td>
<td>70</td>
<td>327</td>
<td>13.5</td>
</tr>
<tr align="right">
<td>1, par</td>
<td>1</td>
<td>157.0</td>
<td>70</td>
<td>327</td>
<td>13.5</td>
</tr>
<tr align="right">
<td>2, par</td>
<td>1</td>
<td> 82.2</td>
<td>72</td>
<td>329</td>
<td>12.7</td>
</tr>
<tr align="right">
<td>1, dist</td>
<td>1</td>
<td>177.2</td>
<td>77</td>
<td>334</td>
<td>11.4</td>
</tr>
<tr align="right">
<td>2, dist</td>
<td>2</td>
<td> 92.2</td>
<td>90</td>
<td>347</td>
<td> 8.6</td>
</tr>
<tr align="right">
<td>4, dist</td>
<td>2</td>
<td> 56.2</td>
<td>112</td>
<td>369</td>
<td> 5.9</td>
</tr>
<tr align="right">
<td>8, dist</td>
<td>2</td>
<td> 58.9</td>
<td>255</td>
<td>516</td>
<td> 1.5</td>
</tr>
<tr align="right">
<td>4, dist</td>
<td>4</td>
<td> 51.2</td>
<td>117</td>
<td>374</td>
<td> 5.5</td>
</tr>
<tr align="right">
<td>6, dist</td>
<td>4</td>
<td> 43.7</td>
<td>129</td>
<td>386</td>
<td> 4.6</td>
</tr>
<tr align="right">
<td>8, dist</td>
<td>4</td>
<td> 62.9</td>
<td>259</td>
<td>519</td>
<td> 1.5</td>
</tr>
<!--
<tr align="right">
<td></td>
<td></td>
<td></td>
</tr>
-->
</table>
</div>
<p>Timings taken on a 16 CPU Intel Xeon SMP computer running 
   at 2.7 GHz and with 32 GB RAM. 
   JVM 1.4.2 started with AggressiveHeap and UseParallelGC. 
   <br />
   #JVMs = number of distinct Java virtual machines.
   #put = number of polynomials put to pair list.
   #remove = number of pairs removed from pair list, 
             i.e. after application of criterions, 
             but including nulls up to now.
   % total = per cent of removed pairs from total pairs generated,
             #remove / ( #put * (#put-1) / 2 ) * 100.
</p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="distributed timings k7g" >
<caption>Distributed computation timings, Katsura 7 (G)</caption>
<tr>
<th># Threads <br /> CPUs</th>
<th># JVMs</th>
<th>time (sec)</th>
<th>#put</th>
<th>#remove</th>
<th>% total</th>
</tr>
<tr align="right">
<td>1, dist</td>
<td>1</td>
<td>24726.2</td>
<td>140</td>
<td>781</td>
<td> 8.0</td>
</tr>
<tr align="right">
<td>2, dist</td>
<td>2</td>
<td>12356.1</td>
<td>165</td>
<td>806</td>
<td> 5.9</td>
</tr>
<tr align="right">
<td>4, dist</td>
<td>4</td>
<td>6859.3</td>
<td>218</td>
<td>859</td>
<td> 3.6</td>
</tr>
<tr align="right">
<td>8, dist</td>
<td>4</td>
<td>7465.1</td>
<td>411</td>
<td>1054</td>
<td> 1.2</td>
</tr>
<tr align="right">
<td>8, dist</td>
<td>8</td>
<td>6412.9</td>
<td>344</td>
<td>986</td>
<td> 1.6</td>
</tr>
<tr align="right">
<td>8, dist</td>
<td>8</td>
<td>7173.3</td>
<td>399</td>
<td>1041</td>
<td> 1.3</td>
</tr>
</table>
</div>
<p>
  Overhead for distributed variant is about 10% in Katsura 6 (G).
  Distributed 1 means one distributed process is running for the
  reduction of S-polynomials. There is always a master process
  handling polynomial input / output, setup and management of 
  distributed workers and handling of the pair list.
  Communication between master and workers is always via TCP/IP
  with object serialization, even if running on one computer.
</p>

</dd>

<dt>2005, 1, 15-16</dt>
<dd> 
  Further things to improve in GB algorithms (from tsp):
  local work queues, i.e. local Pairlists, 
  improve data locality in polynomials and lists,
  communication using message types,
  reduce object serialization in DL-broadcast 
  by using MarshalledObjects,
  reduce communication in Pair send by not sending polynomials
  but indicies (requires distributed hashtable instead of DL),
  interleave communication and computation by adding a 
  communication thread in the distributed client.
<p>
  New classes implementing a distributed hash table to hold the 
  polynomials in distributed GB. Index of polynomials in Pairlist
  is used as hash key.
  Communication is now using message types GBTransportMess.
  Now polynomials are only transported once to each reducer since 
  only polynomial hash indexes are transported.
  Distributed list is asynchronous and late updated, 
  so some duplicate H-polynomials (head terms) could be (are) produced.
  Solution by local put to hash table with dummy index?
  Timings are not dramatically better.
</p>
<p>Todo: check reduction algorithm to use later arriving polynomials.
</p>
</dd>

<dt>2005, 1, 9-14</dt>
<dd> 
  Introduced all direct improvements in util classes found so far.
  (ChannelFactory and others)
  On parallel computers the following JVM options (1.4.2) 
  must be used:
<pre>
  -Xms200M -Xmx400M -XX:+AggressiveHeap -XX:+UseParallelGC
</pre>
  Memory must be adjusted with respect to your situation.
<p>
  Seperated versions with Pair Sequence Respecting Order (PS) and
  normal versions. PS versions try to keep the order of 
  reduced polynomials added to the ideal base the same as in 
  the sequential version.
  Normal versions now running OK on parallel computer with the 
  right JVM options.
  Refactoring with Eclipse (organize imports, static methods).
</p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="parallel timings" >
<caption>Parallel computation timings, Katsura examples</caption>
<tr>
<th># Threads<br />CPUs</th>
<th>Katsura 6 TO(G) <br />load*</th>
<th>Katsura 6 TO(G) <br />empty*</th>
<th>Katsura 7 TO(G) <br />load*</th>
<th>Katsura 7 TO(G) <br />empty*</th>
</tr>
<tr align="right">
<td>seq</td>
<td>184.5</td>
<td>153.3</td>
<td></td>
<td></td>
</tr>
<tr align="right">
<td>1</td>
<td>181.5</td>
<td>4% / 159.7</td>
<td></td>
<td>28418.6</td>
</tr>
<tr align="right">
<td>2</td>
<td>118.6</td>
<td>s2.02 / p2.11 / 75.6</td>
<td></td>
<td>p2.06 / 13760.0</td>
</tr>
<tr align="right">
<td>4</td>
<td>76.8</td>
<td>s3.79 / p3.95 / 40.4</td>
<td>6256.9</td>
<td>p4.56 / 6225.1</td>
</tr>
<tr align="right">
<td>8</td>
<td>43.2</td>
<td>s7.19 / p7.49 / 21.3</td>
<td>3240.7</td>
<td>p8.56/ 3318.8</td>
</tr>
<tr align="right">
<td>10</td>
<td>42.5</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr align="right">
<td>12</td>
<td>40.5</td>
<td></td>
<td>2288.1</td>
<td>p9.90 / 2868.4</td>
</tr>
<tr align="right">
<td>14</td>
<td>31.2</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr align="right">
<td>16</td>
<td>51.9</td>
<td>s8.19 / p8.54 / 18.7</td>
<td>5376.4</td>
<td>p12.59 / 2256.1</td>
</tr>
<!--
<tr align="right">
<td></td>
<td></td>
<td></td>
</tr>
-->
</table>
</div>
<p>Timings taken on a 16 CPU Intel Xeon SMP computer running 
   at 2.7 GHz and with 32 GB RAM. 
   JVM 1.4.2 started with AggressiveHeap and UseParallelGC. 
   <br />
  *) timing taken with other load on the CPUs.
  +) timing taken with no other load on the CPUs.
   <br />
   Speedup: s = relative to sequential, 
            p = relative to parallel with one thread / CPU.
   <br />
   Scaling from 8 to 16 CPUs is bad, but also observed on 
   non CA / GB Examples (Java and C/FORTRAN).
</p>
</dd>

<dt>2004, 10, 3 </dt>
<dd> 
  Generator for Katsura examples (from POSSO / FRISCO examples).
  Timings on an AMD Athlon XP 2800 (2086MHz) with log level INFO.
  Log level WARN would gain 10-20 %.
<div align="center" >
<table border="1" cellpadding="10"
       summary="Timings Katsura examples" >
<caption>Timings Katsura examples</caption>
<tr>
<th>N <br />vars = N+1</th>
<th>TermOrder</th>
<th>Seconds</th>
<th>TermOrder</th>
<th>Seconds</th>
</tr>
<tr align="right">
<td> 7 </td>
<td> G </td>
<td>32044.204</td>
<td> L </td>
<td></td>
</tr>
<tr align="right">
<td> 6 </td>
<td> G </td>
<td>112.641</td>
<td> L </td>
<td></td>
</tr>
<tr align="right">
<td> 5 </td>
<td> G </td>
<td>4.195</td>
<td> L </td>
<td></td>
</tr>
<tr align="right">
<td> 4 </td>
<td> G </td>
<td>0.431</td>
<td> L </td>
<td>11.650</td>
</tr>
<tr align="right">
<td> 3 </td>
<td> G </td>
<td>0.153</td>
<td> L </td>
<td>0.310</td>
</tr>
<tr align="right">
<td> 2 </td>
<td> G </td>
<td>0.031</td>
<td> L </td>
<td>0.032</td>
</tr>
</table>
</div>
</dd>

<dt>2004, 9, 20-26 </dt>
<dd> 
  Changed OrderedPairlist to record the sequence of pairs taken from the list. 
  New methods <code>putParallel()</code>, <code>removeParallel()</code> and 
  helper methods. Sequence numbers are generated and reduced polynomials 
  are only put to the pair list if corresponding pair number is in 
  correct (sequential) sequence. 
  The ordered list / queue <code>pairsequence</code> (TreeMap/SortedMap) 
  keeps track of the polynomials not yet put to the pairlist.
  <br />
  Parallelism is possible as long there are pairs to be reduced.
  But non zero reduced polynomials are only put into the pairlist if
  the polynomial would be put into the pairlist in the sequential 
  Buchberger algorithm.
  GroebnerBase algorithms had to be modified to record that a polynomial
  reduced to zero.
</dd>

<dt>2004, 9, 19 </dt>
<dd> 
  Changed order of Pair inserts for pairs with same LCM of HTs.
  Added sequence number to each Pair and indicator if Pair did not
  reduce to zero.
</dd>

<dt>2004, September </dt>
<dd> 
  Implemented Java server (<code>ExecutableServer</code>) for remote execution 
  of objects implementing the <code>RemoteExecutable</code> interface.
  <p>New setup for the distributed computation of GBs: 
  the GB master now sends the client code to some ExecutableSevers
  based on a maschine file with host and port infos about the 
  distributed environment.
  </p>
  <p>Improved the PolynomialTokenizer so that it can read almost unedited
  old MAS GB input files: <code>**</code> exponents and parenthesis 
  around polynomials. 
  Lines starting with <code>#</code> are treated as comments.
  Comments <code>(* *)</code> and parenthesis within polynomials are 
  still not supported.
  </p>
  <p>Implemented a common driver for GB computations <code>RunGB</code>.
  Sequential, thread parallel and distributed computation can be selected
  by command line parameters. The input is taken from a file. The number 
  of threads respectively the number of distributed clients can be specified.
  For distributed execution the host and port information is taken from 
  a maschines file.
  </p>
<pre>
Usage: RunGB [seq|par|dist|cli] &lt;file&gt; #procs [machinefile]
</pre>
  <p>Added methods <code>putCount()</code> and <code>remCount()</code>
  in <code>OrderedPairlist</code> to count the number of polynomials
  put and get from the pair data structure.
  </p>  
<div align="center" >
<table border="1" cellpadding="10"
       summary="pairlist put and remove" >
<caption>pairlist put and remove, trinks6</caption>
<tr>
<th># Threads</th>
<td>1 seq</td>

<td>1 par</td>
<td>2 par</td>
<td>2 par</td>
<td>3 par</td>
<td>4 par</td>
<td>5 par</td>

<td>1 dist</td>
<td>2 dist</td>
<td>3 dist</td>
<td>4 dist</td>
<td>4 dist</td>
<td>4 dist</td>
<td>5 dist</td>
</tr>
<tr>
<th># put</th>
<td>22</td>

<td>22</td>
<td>43</td>
<td>26</td>
<td>28</td>
<td>28</td>
<td>28</td>

<td>22</td>
<td>25</td>
<td>28</td>
<td>37</td>
<td>40</td>
<td>33</td>
<td>27</td>
</tr>
<tr>
<th># remove</th>
<td>25</td>

<td>25</td>
<td>61</td>
<td>30</td>
<td>32</td>
<td>32</td>
<td>41</td>

<td>26</td>
<td>33</td>
<td>42</td>
<td>47</td>
<td>61</td>
<td>54</td>
<td>69</td>
</tr>
</table>
</div>
  <p>Timings @ 500 MHz on one CPU and one maschine and log4j level INFO are: <br />
  ca. 2.5 - 3.5 seconds for sequential GB,<br />
  ca. 2.5 - 6 seconds for parallel GB,<br />
  ca. 5.5 - 9 seconds plus 5 seconds sync time for distributed GB. <br />
  Network shuffling of polynomials seems to account for 3 seconds in 
  this example.
  </p>
  <p>Problem uncovered: the distributed version of GB needs an 
  avarage of 5 seconds to sync with all clients (on one maschine).
  This is way to much for execution times in the range of 2 to 8 seconds.
  </p>
  <p>Redesign of DistributedList, now using TreeMap to keep the list 
  entries in proper sequence. As key a natural number is used, which is 
  assigned by the server to successive add() requests.
  The server now also holds a copy of the list by itself. So the 
  retransmission of list elements to late arriving clients is possible.
  This doubles the space required to store polynomials, but removes 
  initial delays to sync all clients to receive all list elements.
  <br />
  By retransmission the DistributedList synchronization delay during 
  DistributedGB could be removed.
  However the problem of about 5 seconds delay in startup 
  of DistributedGB still remains. It is not visible where and why this
  delay occurs.
  <br />
  Further improvements would be the removal of list elements or the 
  clearing of the list.
  Next steps could be distributed HashMap or TreeMap.
  <br />
  An important improvement would be to keep serialized copies of the 
  list elements (polynomials) at the server and to 
  avoid many time serialization during broadcast.
  </p>
</dd>

<dt>2004, 2, 26</dt>
<dd>
  Ideas to implement: 
  a distributed task launcher like <code>mpirun</code>,
  a daemon to run on a distributed system to work with the launcher,
  solvable polynomials and non-commutative GBs.
</dd>

<dt>2004, 2, 1</dt>
<dd>
   Parallel computations with the Rose example are at ?? h with 3 threads
   on 2 Pentium 4 @ 3.0 GHz hyperthreading CPUs. 
   <p>With one thread the time is 30.6 h. 
   Besides the better CPU speed, this makes a 5 % improvement on JDK 1.4 
   compared to the older timings from a JDK 1.3 
   and the new polynomial implementation.
 </p>
</dd>

<dt>2004, 1, 25</dt>
<dd>
Spin model checker:
Setup Promella description of parallel and distributed GB algorithm.
Used to verify the safety and liveness properties of the algorithms.
</dd>

<dt>2004, 1, 17</dt>
<dd>
New (minimal) class DistributedList in preparation of a 
distributed GB algorithm.
Made all mutually transported objects Serializable.
Fixed ChannelFactory and other classes in edu.unima.ky.parallel 
to be interuptable.
Moved Semaphore back to edu.unima.ky.parallel.
First version of a distributed memory GB.
One problem was inner class Pair results in serialization 
of outer class OrderedPairlist, which is not intented. 
So Pair is now a proper class.
Distributed version mainly working. 
Problem with signaling and termination if 1 in GB.
</dd>

<dt>2004, 1, 10</dt>
<dd>
Refactored Groebner base for new OrderedPolynomials and
split sequential and parallel GB implementations.
New unit tests for sequential and parallel GBs.
GB now works for arbitrary Coefficients.
</dd>

<dt>2004, 1, 5</dt>
<dd>
New coefficient domains BigComplex and BigQuaternion. 
New test unit for all coefficients.
Based on these coefficients are new polynomials, e.g. 
ComplexOrderedMapPolynomial and QuatOrderedMapPolynomial
together with unit tests.
Problem: RatPolynomial requires DEFAULT_EVORD be set correctly in ExpVector.
This is now solved for the new OrderedMapPolynomials.
</dd>

<dt>2003, 12, 29</dt>
<dd>
New organization of polynomials: 
<br />
2 interfaces: UnorderedPolynomial and OrderedPolynomial. 
Ordered polynomials have a term order and are implemented using 
some SortedMap (e.g. TreeMap).
Unodered polynomials are implemented using some HashMap (e.g. LinkedHashMap).
<br />
2 abstract classes: UnorderedMapPolynomial and OrderedMapPolynomial.  
Both implement all algorithms which do not need an explicit coeficient domain, 
i.e. they are formulated in terms of the Coefficient interface from jas.arith.
<br />
2 or more classes which extend the respective abstract classes: 
RatUnorderedMapPolynomial and RatOrderedMapPolynomial both need explicitly 
coefficients from BigRational or others. 
<p>
Multiplication with ordered polynomials is about 8-10 times faster than 
the multiplication with unordered polynomials. Also the multiplication with 
semi-ordered polynomials (LinkedHashMap) with orderpreserving addition is
about 7-8 times slower than multiplication with ordered polynomials.
</p>
<p>
All implementations are based on Map interface and classes. 
The Map maps exponent vectors (from some monoid) to coefficients (from some domain). 
This is in sync with the mathematical definition of multivariate polynomials 
as mappings from some monoid to some domain.
Term orders are represented by a TermOrder class which provides the 
desired Comparator classes for the SortedMap implementation. 
</p>
</dd>

<dt>2003, 12, 28</dt>
<dd>Things to do: 
refactor and test HashPolynomial, check performance.
Improve the parallel GB algorithm, e.g. parallelize the reduction algorithm. 
Develop a distributed memory version of the parallel GB algorithm.
</dd>

<dt>2003, 12, 27</dt>
<dd>Using ArgoUML to produce class diagramms for jas.
    Refactoring GB from edu.jas.poly to edu.jas.ring.
</dd>

<dt>2003, 12, 21</dt>
<dd>Setup for JUnit version 3.8.1. 
Added JUnit testing with Apache Ant version 1.6.0 to build.xml. 
</dd>

<dt>2003, September</dt>
<dd>
  Experimented with LinkedHashMap instead of TreeMap (SortedMap) 
  for the representation of polynomials. 
  Algorithms which work also with LinkedHashMap have 1 or 2 in their names
  (now in new class HashPolynomial).
  LinkedHashMap has the property of using the insertion order for 
  the iterator order.
  With LinkedHashMap the add() and subtract() can be reformulated to 
  use a merging algorithm as in the original DIP implementation.
  Assuming the Map insertion order is the the same as the polynomial
  term order.
  <p>
  However the merging add/subtact implementation is a factor of 
  2 slower than the TreeMap implementation. 
  Complexity for a+b is <br />
  2*(length(a)+length(b)) 
    for access and merging pre sorted polynomials and 
  <br />
  2*length(a)+length(b)+length(b)*log2(length(a+b)) 
    for TreeMap clone, access and insertion.
  </p>
  <p>
  The merging multiplication implementation is by a factor of 
  10 slower than the TreeMap implementation. 
  Polynomial size was ~100 terms and the product contained ~8000 terms.
  Complexity for a*b is 
  <br />
  lab = length(a)*length(b) coefficient multiplications for both implementations
  <br />
  plus 2*length(a*b)*length(b) for merging summands, respectively 
  <br />
  plus length(a)*length(b)*log2(length(a*b)) for TreeMap insertion.
  Since for sparse polynomials length(a*b) = lab, the TreeMap complexity 
  is asymptotically better in this case:<br />
     2*length(a)*length(b)*length(b) =&gt;= length(a)*length(b)*log2(length(a*b))
  <br />
  For dense polynomials with length(a*b) ~ length(a)[+length(b)], then 
  the LinkedHashMap complexity is asymptotically better:
  <br />
     2*length(a)*length(b) =&lt;= length(a)*length(b)*log2(length(a*b))
  </p>
</dd>

<dt>2003, 3, 15</dt>
<dd>
   Some testing with new 
   AMD Athlon XP 2200+ @ 1.8 GHz, 133x2 MHz memory access.<br />
   Trinks 6: 1.013 sec with log4j level WARN, parallel 1.058 - 1.740 sec.<br />
   Trinks 7: 0.553 sec with log4j level WARN.<br />
</dd>

<dt>2003, 2, 2 </dt>
<dd>
   Replacing all System.out.println by Log4j logging calls.
   adding some Junit tests.
</dd>

<dt>2003, 1, 28 </dt>
<dd>
   Some testing with gcj (Gnu Java Compiler). this compiler gernerates 
   native executable binaries. the timings are not better than with
   a jit, often worser.
   <p>Parallel computations with the Rose example are at 18 h with 4 threads
   on 2 Pentium 4 @ 2.4 GHz hyperthreading CPUs. With one thread the time
   is 40 h. 
 </p>
</dd>

<dt>2003, 1, 26 </dt>
<dd>
    timings with JDK 1.3 (from IBM) are 30% to 40% faster 
    than with JDK 1.4.1 (from Sun).
    timings on PowerPC 604 @ 200MHz JDK 1.3 (from IBM) 
    JDK 1.2 (from Sun) are a factor 3.5-4.5 slower than on Intel PIII @ 450 MHz.
    on PowerPC not using jit is faster than using a jit, ca. 20% - 30%.
</dd>

<dt>2003, 1, 12 </dt>
<dd>
    General differences between sequential and parallel GB algorithms
    <ul>
    <li>The parallelization is achieved by doing the normal form reductions
        in parallel.
    </li>
    <li>Since the reductions may require different times to complete 
        the normal forms may be entered into the list of polynomials
        in different (time) order than in the sequential case. 
        So the pairs may be generated in different order.
        However since the list of pairs is ordered wrt. the lcm of 
        the head terms this seems not to be a big issue. 
    </li>
    <li>Since several reductions are scheduled in parallel 
        the pairs are taken from the list of pairs in different order
        than in the sequential case.
        One should not take more pairs from the list than can be reduced
        in parallel. 
    </li>
    </ul>
    <p class="note">Does this influence the validity of criterion 3?
       Access to pairlist is synchronized. 
       Pairs are marked as reduced as soon they are taken from the list.
       But the algorithm terminates only after all reductions of pairs have
       terminated. So criterion 3 holds.
    </p>
    <p>New implementation of parallel version of GB.
       Removal of pairs is now also in parallel.
       But ordering of pair insertion is no more preserved
    </p>
    <p>Timings are more stable 
       and slightly better than that of sequential GB.
    </p>
    <p>Todo: unit tests, comments, ...
    </p> 
</dd>

<dt>2003, 1, 7-11 </dt>
<dd>
    Renamed jas to mas2jas, 
    new cvs repository for jas, import and checkout.
    <p>Improved parallel version of GB.
    </p>
    <ul>
    <li>The sequence of polynomials added to the pair list is kept 
        stable. i.e. a pair scheduled for reduction at time t 
        will (if non zero) enter the list before any pair 
        scheduled at time t+x. 
    </li>
    <li>This limits the parallelism since polynomials which reduce to zero
        keep a reducer thread occupied until older polynomials are 
        finally reduced. One could eventualy hand over the blocking
        object to the next thread. 
    </li>
    <li>The number of pairs scheduled for reduction is now also limited
        to the number of parallel reduction threads. this avoids
        that to many pairs with high lcm will be scheduled before 
        eventually new created pairs with lower lcm.
    </li>
    <li>The limiting of scheduled pairs could also be implemented using
        a BoundedBuffer/Queue for the ThreadPool workpile.
        then addJob() would block until free Threads are avalilable.
    </li>
    <li>The sequencing and limiting could eventually also 
        achieved when the reducing threads take the pairs by 
        themselves instead of the master thread.
        The main thread should then simply wait until all
        threads are idle.
    </li>
    <li>The final reduction of the GB to a minimal GB is now 
        also parallelized.
    </li>
    </ul>
   <p>
   Todo: CVS, comments, 
   polynomial implementation using LinkedList,
   parallel GB simplify
   </p>
<p>With the improved algorithm the running time of the parallel GB
   becomes more stable and not slower than the sequential GB.
   However there is still no significant speedup.
</p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="number of reductions" >
<caption>parallel GB on one cpu</caption>
<tr>
<th># Threads</th>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>16</td>
</tr>
<tr>
<th># Reductions</th>
<td>25</td>
<td>25</td>
<td>27</td>
<td>25</td>
<td>25</td>
<td>25</td>
<td>25</td>
<td>25</td>
<td>25</td>
</tr>
</table>
</div>
<p></p>
<div align="center" >
<table border="1" cellpadding="10"
       summary="number of reductions" >
<caption>parallel GB on 4 cpus</caption>
<tr>
<th># Threads</th>
<td>1</td>
<td>2</td>
<td>3</td>
<td>4</td>
<td>5</td>
<td>6</td>
<td>7</td>
<td>8</td>
<td>16</td>
</tr>
<tr>
<th># Reductions</th>
<td>22</td>
<td>24</td>
<td>30, 28, 24, 29</td>
<td>28</td>
<td>29</td>
<td>42</td>
<td>32</td>
<td>32</td>
<td>37</td>
</tr>
</table>
</div>
<p></p>
</dd>

<dt>2003, 1, 6 </dt>
<dd>implemented parallel version of GB using ThreadPool from tnj
    <p>
    parallel results: <br />
    Trinks 7: mas 0.598 sec, jas 0.918 sec, jas par 0.955 sec <br />
    Trinks 6: mas 26.935 sec, jas 3.211 sec, jas par 3.656 sec <br />
    mas: including startup and gc time,
    jas: excluding startup of jvm and including gc time,
    jas par on single processor
    timing on P-3@450
    </p>
    this make for a penality of 12 percent,
    all tests with output to files,
</dd>

<dt>2003, 1, 5 </dt>
<dd>timing benchmarks between BigRational and Coefficient versions
    of the algorithms,
    the difference seems to be less than 1 percent with 
    no clear advantage of one side
    <br />
    the sum and product algorithms have not jet optimal complexity,
    sum has 2 l log(l) instead of 2 l 
        because of TreeMap.remove() and because of TreeMap.put(),
    prod has l^2 log(l^2/2) instead of l^2 because of TreeMap.put()
    <br />
    TreeMap cannot used for this,
    some kind of SortedLinkedList or SortedHashMap would be required,
    the last would in turn require a hashValue() of an ExpVector
    <p>
    implemented edu.jas.arith.BigInteger which implements Coefficient,
    tested with IntPolynomial which extends Polynomial
    </p>
    todo: alternative Implementations, cleanup RatPolynomial, parallel GB,
    conversion RatPolynomial &lt;--&gt; IntPolynomial
</dd>

<dt>2003, 1, 4 </dt>
<dd>added reading of PolynomialLists and Variable Lists to 
    PolynomialTokenizer, 
    implemented PolynomialList
    <br />
    refactoring RatPolynomial to extend Polynomial,
    implementing IntPolynomial extends Polynomial
    <br />
    to make BigInteger implement Coefficient will require 
    a delegation extension of BigInteger
</dd>
<!--  -->
<dt>2003, 1, 3 </dt>
<dd>implemented PolynomialTokenizer to read RatPolynomials 
</dd>

<dt>2003, 1,  2</dt>
<dd>file RatPolynomial split into RatGBase,
    criterion 3 implemented with BitSet
    <p>
    second results (with new criterion 3 in jas): <br />
    Trinks 7: mas 0.598 sec, jas 1.159 sec <br />
    Trinks 6: mas 26.935 sec, jas 6.468 sec <br />
    mas: including startup and gc time,
    jas: excluding startup of jvm and including gc time 
    </p>
    implemented DIGBMI, H-polynomal was not monic in DIRPGB
    <p>
    third results (with new criterion 3 in jas and GBminimal): <br />
    Trinks 7: mas 0.598 sec, jas 0.918 sec <br />
    Trinks 6: mas 26.935 sec, jas 3.211 sec <br />
    mas: including startup and gc time,
    jas: excluding startup of jvm and including gc time 
    timing on P-3@450
    </p>
    <p>
    this makes for a factor of 8-9 better,
    all tests with output to files,
    startup of JVM is approx. 1.0-1.2 sec,
    most time is spent in BigInteger:
    </p>
<pre>
java -Xrunhprof:cpu=times,format=a

CPU TIME (ms) BEGIN (total = 136) Thu Jan  2 18:33:53 2003
rank   self  accum   count trace method
   1 15,44% 15,44%  596610    21 java.math.MutableBigInteger.rightShift
   2 13,24% 28,68%  582132    15 java.math.MutableBigInteger.difference
   3 12,50% 41,18%  612760    19 java.math.MutableBigInteger.getLowestSetBit
   4  9,56% 50,74%       2     9 java.lang.Object.wait
   5  9,56% 60,29%    5271    22 java.math.MutableBigInteger.binaryGCD
   6  6,62% 66,91%  612760    23 java.math.BigInteger.trailingZeroCnt
   7  5,88% 72,79%  592152    18 java.math.BigInteger.bitLen
   8  5,88% 78,68%    6018    20 java.math.MutableBigInteger.binaryGCD
   9  5,15% 83,82%  578887    25 java.math.MutableBigInteger.normalize
  10  4,41% 88,24%  550992    24 java.math.MutableBigInteger.primitiveRightShift
  11  4,41% 92,65%       1    10 java.lang.Object.wait
  12  3,68% 96,32%  582132    12 java.math.MutableBigInteger.compare
  13  0,74% 97,06%   35965    13 edu.jas.poly.ExpVector.EVILCP
  14  0,74% 97,79%   11612    14 java.math.BigInteger.divide
  15  0,74% 98,53%    5866    11 java.math.MutableBigInteger.divide
  16  0,74% 99,26%    9032    16 java.math.MutableBigInteger.divide
  17  0,74% 100,00%   9032    17 java.math.BigInteger.divide
CPU TIME (ms) END
</pre>
</dd>

<dt>2003, 1,  1</dt>
<dd>renaming packages to edu.jas,
    renaming to arith, poly and ring,
    new Makefile, project dokumentation in XHTML,
    using JDK 1.4 with JIT 
    <p>
    first results (without criterion 3 in jas): <br />
    Trinks 7: mas 0.598 sec, jas 1.373 sec <br />
    Trinks 6: mas 26.935 sec, jas 30.935 sec <br />
    mas: including startup and gc time, 
    jas: excluding startup of jvm and including gc time.
    timing on P-3@450
    </p>
</dd>

<dt>2002, 12,  31</dt>
<dd>starting with extraction of relevant files in new directory <br /> 
</dd>

<dt>2000, 7,  21</dt>
<dd>keySet/get replaced by entrySet/getval. <br />
    Implemented S-Polynomial, normal form, irreducible set.
    Implemented Groebner base with criterion 4. Criterion 3 left to to.
</dd>

<dt>2000, 7, 16</dt>
<dd>Implemented and tested BigRational based on Javas BigInteger.<br />
    With and without I/O BigRational addition, multiplication and 
    comparison is approx. 10 times faster than respective 
    SACRN functions.<br />    
    <p>Implemented and testet ExpVector based on Javas int arrays. 
    </p>
    <p>Implemented and testet RatPolynomial based on Javas TreeMap. <br />
       static methods: DIRPDF, DIRPWR via toString, DIRPON, DIRPMC, 
       DIRPPR, DIRPSM, DIRRAS.<br />
       Consider replacing keySet/get by entrySet/getval where appropriate.
       Can there be an generic Polynomial class?
    </p>
</dd>

<dt>2000, 7, 15</dt>
<dd>Some testing with Javas builtin BigInteger class.<br />
    Without I/O builtin multiplication is approx. 15 times faster 
            than SAC product.<br />
    With much I/O builtin multiplication is approx. 3 times faster 
            than SAC product.<br />
    Builtin uses also twos-complement representation, which is
    bad for decimal printing.
    <p>This will be the end of list processing for Jas.</p>
    <p>
   DIPRNGB needs DIRPDF, DIRPWR, DIRPON, DIRPMC, DIRPPR, DIRPSM.<br />
   These need RNDIF, RNDWR, RNINT, RNSIGN, ISRNONE, RNONE, RNZERO,
         RNINV (and DIRPRP), RNPROD, RNSUM.
   </p>
</dd>

<dt>2000, 7, 14</dt>
<dd>Class BigInteger based on SACI with toString().<br /> 
    Class List based on MASSTOR with toString(). <br />
    Problem with Modula-2 module initialization with main(args) 
    method: initialization of static variables.
</dd>

<dt>2000, 7, 5</dt>
<dd>Finished testing most of masarith. 
</dd>

<dt>2000, 7, 2</dt>
<dd>Finished porting masarith. 
    Testing needs still to be done. MASAPF is ok.
</dd>

<dt>2000, 6, 24</dt>
<dd>Perl script getc.pl to grab comments in Modula-2 source 
    and add to Java source. 
    Comments grabbed on most working files so far.
    Generated new documentation.
</dd>

<dt>2000, 6, 22</dt>
<dd>Future directions:
    <ul>
    <li>Parallel GB.
    </li>
    <li>Move to Java without Modula-2.
    </li>
    <li>Develop an applet version.
    </li>
    <li>Implement more of Mas.
    </li>
    <li>Replace SACI by Java BigInteger.
    </li>
    <li>Setup for real objects: <br />
        implement constructor, <br />
        implement methods: a.method(b) as STATIC_METHOD(a,b), <br />
        use real objects instead of only Cell objects <br />
        define interfaces e.g. for ring, polynomial ring, 
                                   module, group, field
    </li>
    <li>Small additions: <br />
        toString equivalents of xWRITEs
    </li>
    </ul>
    Problems identified:
    <ul>
    <li>LISTs over Beta-Integers are diffrent to LISTs over LISTs,
        when implementing LISTs as Java Types
        LISTs over other types will require also special handling.
    </li>
    </ul>
</dd>

<dt>2000, 6, 22</dt>
<dd>GB running on Trinks (small and big). 
    Jas ist about 5-8 times slower than MAS in GB computation.
    Using JDK 1.1.7 without JIT on Linux, PII-300.
    Using JDK 1.2.2-RC3 without JIT on Linux, PII-300 is 
    about 6-9 times slower.
    Using JDK 1.2.2-RC4 with JIT (sunwjit) on Linux, PII-300 is 
    about 2-4 times slower.
    Implemented Java input via BufferedReader.
</dd>

<dt>2000, 6, 21</dt>
<dd>Got GB running. Problem was in EQUAL.
</dd>

<dt>2000, 6, 17</dt>
<dd>Placed under control of CVS.
    Begining with a clean version from Uni Passau.
    Incorporated Java specific changes up to now.
</dd>

<dt>2000, 6, 10</dt>
<dd>Transformation of DIPRNGB finished.
    Important parts of maspoly finished.
</dd>

<dt>2000, 6, 4</dt>
<dd>Transformation of SACPRIM finished.
    Most of maskern finished.
    Important parts of masarith finished.
</dd>

<dt>2000, 5, 29</dt>
<dd>MASSTOR: Mapping MAS list direkt to a Java list class and using 
    of the garbage collector from Java. 
    Data types LIST and GAMMAINT are now distinct.
    Buying the MHC Compiler (UK Pound 59).
</dd>

<dt>2000, 5, 28</dt>
<dd>MASSTOR: First attempt to use list class with own garbage collection.
    Using the constructor to record list pointers.
</dd>

<dt>2000, 5, 27: </dt>
<dd>Beginning of the first tests. 
    Conversion of .md to .def, .mi to .mod.
</dd>

<dt>2000, 5, 26: </dt>
<dd>Discovery of the MHC Modula-2 to Java compiler. 
    Mill Hill &amp; Canterbury Corporation, Ltd, URL
    <a href="http://www.mhccorp.com">http://www.mhccorp.com</a>
</dd>

</dl>


<h2>To Do</h2>

<ul>
<li>Applet front-end.
</li>
<li><del>Reimplementing MASBIOS for streams.</del>
</li>
<li>Copying the comments to java.
</li>
</ul>


<h2>Done</h2>

<ul>
<li>JUnit checker for every class.
</li>
<li>Switching to Java and abandoning Modula-2.
</li>
<li>Removal of the mas prefix in directory names.
</li>
<li>Improved Makefiles.
</li>
</ul>


    <hr />
    <address><a href="mailto:kredel@at@rz.uni-mannheim.de">Heinz Kredel</a></address>
<p>
<!-- Created: Sun Jun  4 12:58:30 MEST 2000 -->
<!-- hhmts start -->
Last modified: Thu Oct  2 22:02:24 CEST 2008
<!-- hhmts end -->
</p>
<!--p align="right" >
$Id: jas-log.html 2156 2008-10-02 20:02:41Z kredel $
</p-->
  </body>
</html>
